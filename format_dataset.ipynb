{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3eed89-753f-41e4-b125-01df98d2d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eccfbcd-7a11-4548-bd48-78ea3d2fa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../6m_mix.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b523824-8134-4ba8-81ce-06564838dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>spell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chây ì noojp phạt nguội .</td>\n",
       "      <td>Chây ì nộp phạt nguội .</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mây là á phương tiện vi phạm dc camera ( di dd...</td>\n",
       "      <td>Đây là các phương tiện vi phạm được camera ( d...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phổ biến nhất là lỗi ỗ không đúng nơi quy định .</td>\n",
       "      <td>Phổ biến nhất là lỗi đỗ không đúng nơi quy định .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                          Chây ì noojp phạt nguội .   \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...   \n",
       "2  mây là á phương tiện vi phạm dc camera ( di dd...   \n",
       "3   Phổ biến nhất là lỗi ỗ không đúng nơi quy định .   \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                            Chây ì nộp phạt nguội .   \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...   \n",
       "2  Đây là các phương tiện vi phạm được camera ( d...   \n",
       "3  Phổ biến nhất là lỗi đỗ không đúng nơi quy định .   \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...   \n",
       "\n",
       "                                               spell  \n",
       "0                                 [0, 0, 1, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "3               [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b247630c-daea-4467-82b9-3355e8348310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from utils import *\n",
    "\n",
    "class PhoBertDataset(Dataset):\n",
    "    def __init__(self, indexs,\n",
    "                 token_ids=None,\n",
    "                 data=None,\n",
    "                 is_train: bool = True,\n",
    "                 ):\n",
    "        self.indexs = indexs\n",
    "        self.n_errors = 2\n",
    "        self.mask_token_id = 0\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.token_ids = token_ids\n",
    "            self.correct_token_ids = self.token_ids['correct_token_ids']\n",
    "            self.n_words = self.token_ids['n_words']\n",
    "            self.error_ids = self.token_ids['error_ids']\n",
    "            self.label_errors = self.token_ids['label_errors']\n",
    "            self.size_subwords = self.token_ids['size_subwords']\n",
    "        else:\n",
    "            self.data = data\n",
    "            self.word_error_tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "            self.error_ids = tokenizer_ids(self.data.error_sentence, self.word_error_tokenizer)\n",
    "            self.size_subwords = calculate_size_subword(self.data.error_sentence, self.word_error_tokenizer)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            idx = self.indexs[idx]\n",
    "        data = {'error_id': torch.tensor(self.error_ids[idx], dtype=torch.long)}\n",
    "        data['attention_mask'] = torch.tensor([0] + [1] * (data['error_id'].size(0) - 2) + [0], dtype=torch.long)\n",
    "        data['batch_split'] = self.size_subwords[idx]\n",
    "        if self.is_train:\n",
    "            data['label_error'] = torch.tensor(self.label_errors[idx])\n",
    "            data['word_correction'] = torch.tensor(self.correct_token_ids[idx])\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83e8e5f3-3ca6-4c38-b3ac-62a8bbb77f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebeeba89-77b2-4ff1-bd5d-92b2bcee024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92763ee9-8a1c-4c74-8d2a-c181f3ce1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dts.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17048684-5a9a-4889-b428-578d072f34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'spell'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19aa3397-6161-4000-af9a-d8426a51924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671af4bd4a904cee9eaa6ebaf71fb50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mapping_tokenizer(examples):\n",
    "    examples['correct_token_ids'] = tokenizer(examples['summary'])['input_ids'][1:-1]\n",
    "    examples['error_ids'] = tokenizer(examples['text'])['input_ids']\n",
    "    examples['label_errors'] = eval(examples['spell'])\n",
    "    del examples['spell']\n",
    "    examples['batch_split'] = calculate_size_subword([examples['text']], tokenizer)[0]\n",
    "    return examples\n",
    "\n",
    "dataset = dataset.map(mapping_tokenizer, batched=False, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d08c44cf-0522-4d06-949b-fe66a49e34c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Hàng chục ngàn phương tiện bị ghi hình vi phạm luật giao thông ở TP . HCM , bị ' bêu tên ' nhưng chủ van không chịu nộp phạt .\",\n",
       " 'summary': \"Hàng chục ngàn phương tiện bị ghi hình vi phạm luật giao thông ở TP . HCM , bị ' bêu tên ' nhưng chủ vẫn không chịu nộp phạt .\",\n",
       " 'correct_token_ids': [1383,\n",
       "  781,\n",
       "  1232,\n",
       "  1607,\n",
       "  5959,\n",
       "  45,\n",
       "  701,\n",
       "  819,\n",
       "  5237,\n",
       "  2283,\n",
       "  1252,\n",
       "  574,\n",
       "  2178,\n",
       "  25,\n",
       "  253,\n",
       "  5,\n",
       "  383,\n",
       "  4,\n",
       "  45,\n",
       "  104,\n",
       "  31742,\n",
       "  221,\n",
       "  104,\n",
       "  51,\n",
       "  286,\n",
       "  74,\n",
       "  17,\n",
       "  551,\n",
       "  1140,\n",
       "  1133,\n",
       "  5],\n",
       " 'error_ids': [0,\n",
       "  1383,\n",
       "  781,\n",
       "  1232,\n",
       "  1607,\n",
       "  5959,\n",
       "  45,\n",
       "  701,\n",
       "  819,\n",
       "  5237,\n",
       "  2283,\n",
       "  1252,\n",
       "  574,\n",
       "  2178,\n",
       "  25,\n",
       "  253,\n",
       "  5,\n",
       "  383,\n",
       "  4,\n",
       "  45,\n",
       "  104,\n",
       "  31742,\n",
       "  221,\n",
       "  104,\n",
       "  51,\n",
       "  286,\n",
       "  4616,\n",
       "  17,\n",
       "  551,\n",
       "  1140,\n",
       "  1133,\n",
       "  5,\n",
       "  2],\n",
       " 'label_errors': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'batch_split': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c867ef9-1e2a-402f-a8f6-dd5c80c9967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ch@@', 'ây', 'ì', 'nộp', 'phạt', 'nguội', '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Chây ì nộp phạt nguội .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cc6ad-f03b-4509-b1b0-2158991bd544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
