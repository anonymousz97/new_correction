{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f3eed89-753f-41e4-b125-01df98d2d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9eccfbcd-7a11-4548-bd48-78ea3d2fa143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../6m_mix.csv\", nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4068db54-62fc-450f-ab7a-2fb5c9cf8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def split_punctuation(text):\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i, \" \"+i+\" \")\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b523824-8134-4ba8-81ce-06564838dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>spell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chây ì noojp phạt nguội .</td>\n",
       "      <td>Chây ì nộp phạt nguội .</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mây là á phương tiện vi phạm dc camera ( di dd...</td>\n",
       "      <td>Đây là các phương tiện vi phạm được camera ( d...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phổ biến nhất là lỗi ỗ không đúng nơi quy định .</td>\n",
       "      <td>Phổ biến nhất là lỗi đỗ không đúng nơi quy định .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                          Chây ì noojp phạt nguội .   \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...   \n",
       "2  mây là á phương tiện vi phạm dc camera ( di dd...   \n",
       "3   Phổ biến nhất là lỗi ỗ không đúng nơi quy định .   \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                            Chây ì nộp phạt nguội .   \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...   \n",
       "2  Đây là các phương tiện vi phạm được camera ( d...   \n",
       "3  Phổ biến nhất là lỗi đỗ không đúng nơi quy định .   \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...   \n",
       "\n",
       "                                               spell  \n",
       "0                                 [0, 0, 1, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "3               [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3009125-f87d-41f4-965d-6c83d054db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x : split_punctuation(x))\n",
    "df['summary'] = df['summary'].map(lambda x : split_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0cdaf9b8-6e0c-4a34-9561-427ee5bc1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_row = []\n",
    "lst_summary = []\n",
    "lst_spell = []\n",
    "for idx, row in df.iterrows():\n",
    "    if len(row['text'].split(' ')) != len(row['summary'].split(' ')):\n",
    "        continue\n",
    "    spell = []\n",
    "    for i, j in zip(row['text'].split(' '), row['summary'].split(' ')):\n",
    "        if i == j:\n",
    "            spell.append(0)\n",
    "        else:\n",
    "            spell.append(1)\n",
    "    lst_row.append(row['text'])\n",
    "    lst_summary.append(row['summary'])\n",
    "    lst_spell.append(spell)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame({\"text\":lst_row, \"spell\":lst_spell, \"summary\": lst_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8cfb794-2e70-4ef1-a05c-583c1a11007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spell</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chây ì noojp phạt nguội .</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>Chây ì nộp phạt nguội .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Hàng chục ngàn phương tiện bị ghi hình vi phạm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mây là á phương tiện vi phạm dc camera ( di dd...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>Đây là các phương tiện vi phạm được camera ( d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phổ biến nhất là lỗi ỗ không đúng nơi quy định .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Phổ biến nhất là lỗi đỗ không đúng nơi quy định .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                          Chây ì noojp phạt nguội .   \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...   \n",
       "2  mây là á phương tiện vi phạm dc camera ( di dd...   \n",
       "3   Phổ biến nhất là lỗi ỗ không đúng nơi quy định .   \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...   \n",
       "\n",
       "                                               spell  \\\n",
       "0                                 [0, 0, 1, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "3               [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             summary  \n",
       "0                            Chây ì nộp phạt nguội .  \n",
       "1  Hàng chục ngàn phương tiện bị ghi hình vi phạm...  \n",
       "2  Đây là các phương tiện vi phạm được camera ( d...  \n",
       "3  Phổ biến nhất là lỗi đỗ không đúng nơi quy định .  \n",
       "4  Chẳng hạn từ tháng 1 - 7 . 2017 , ô tô BS : 14...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b247630c-daea-4467-82b9-3355e8348310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from utils import *\n",
    "\n",
    "class PhoBertDataset(Dataset):\n",
    "    def __init__(self, indexs,\n",
    "                 token_ids=None,\n",
    "                 data=None,\n",
    "                 is_train: bool = True,\n",
    "                 ):\n",
    "        self.indexs = indexs\n",
    "        self.n_errors = 2\n",
    "        self.mask_token_id = 0\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.token_ids = token_ids\n",
    "            self.correct_token_ids = self.token_ids['correct_token_ids']\n",
    "            self.n_words = self.token_ids['n_words']\n",
    "            self.error_ids = self.token_ids['error_ids']\n",
    "            self.label_errors = self.token_ids['label_errors']\n",
    "            self.size_subwords = self.token_ids['size_subwords']\n",
    "        else:\n",
    "            self.data = data\n",
    "            self.word_error_tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "            self.error_ids = tokenizer_ids(self.data.error_sentence, self.word_error_tokenizer)\n",
    "            self.size_subwords = calculate_size_subword(self.data.error_sentence, self.word_error_tokenizer)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            idx = self.indexs[idx]\n",
    "        data = {'error_id': torch.tensor(self.error_ids[idx], dtype=torch.long)}\n",
    "        data['attention_mask'] = torch.tensor([0] + [1] * (data['error_id'].size(0) - 2) + [0], dtype=torch.long)\n",
    "        data['batch_split'] = self.size_subwords[idx]\n",
    "        if self.is_train:\n",
    "            data['label_error'] = torch.tensor(self.label_errors[idx])\n",
    "            data['word_correction'] = torch.tensor(self.correct_token_ids[idx])\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83e8e5f3-3ca6-4c38-b3ac-62a8bbb77f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ebeeba89-77b2-4ff1-bd5d-92b2bcee024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92763ee9-8a1c-4c74-8d2a-c181f3ce1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dts.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17048684-5a9a-4889-b428-578d072f34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'spell', 'summary'],\n",
       "    num_rows: 969\n",
       "})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19aa3397-6161-4000-af9a-d8426a51924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4281f0cfa3b44f98a77ad8688b8e7c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/969 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mapping_tokenizer(examples):\n",
    "    examples['correct_token_ids'] = tokenizer(examples['summary'])['input_ids']\n",
    "    examples['error_ids'] = tokenizer(examples['text'])['input_ids']\n",
    "    examples['label_errors'] = [0] + eval(str(examples['spell'])) + [0]\n",
    "    del examples['spell']\n",
    "    examples['batch_split'] = [1] + calculate_size_subword([examples['text']], tokenizer)[0] + [1]\n",
    "    return examples\n",
    "\n",
    "dataset = dataset.map(mapping_tokenizer, batched=False, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d08c44cf-0522-4d06-949b-fe66a49e34c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[1]['error_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c867ef9-1e2a-402f-a8f6-dd5c80c9967a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_size_subword(['<s> Trong 5 thập kỷ qua, dân số thị trấn này đã giảm gần một nửa, tư2 2, 25 0 ngườo xuống chỉ còn 1. 30 0 người do số lượng trẻ sơ sinh quá thấp. </s>'], tokenizer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "361cc6ad-f03b-4509-b1b0-2158991bd544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Trong',\n",
       " '5',\n",
       " 'thập',\n",
       " 'kỷ',\n",
       " 'qua@@',\n",
       " ',',\n",
       " 'dân',\n",
       " 'số',\n",
       " 'thị',\n",
       " 'trấn',\n",
       " 'này',\n",
       " 'đã',\n",
       " 'giảm',\n",
       " 'gần',\n",
       " 'một',\n",
       " 'nử@@',\n",
       " 'a@@',\n",
       " ',',\n",
       " 'tư@@',\n",
       " '2',\n",
       " '2@@',\n",
       " ',',\n",
       " '25',\n",
       " '0',\n",
       " 'ngườ@@',\n",
       " 'o',\n",
       " 'xuống',\n",
       " 'chỉ',\n",
       " 'còn',\n",
       " '1.',\n",
       " '30',\n",
       " '0',\n",
       " 'người',\n",
       " 'do',\n",
       " 'số',\n",
       " 'lượng',\n",
       " 'trẻ',\n",
       " 'sơ',\n",
       " 'sinh',\n",
       " 'quá',\n",
       " 'thấ@@',\n",
       " 'p.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('<s> Trong 5 thập kỷ qua, dân số thị trấn này đã giảm gần một nửa, tư2 2, 25 0 ngườo xuống chỉ còn 1. 30 0 người do số lượng trẻ sơ sinh quá thấp. </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5da698c0-e298-4777-aa4b-560306fb60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_ds = {\"error_ids\":dataset['error_ids'],\"label_errors\":dataset['label_errors'],\"size_subwords\":dataset['batch_split']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ec8c177-51f5-4d79-8a08-52f8f03904d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('sample_dataset.pkl', 'wb') as handle:\n",
    "    pickle.dump(format_ds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "978f983c-e922-416a-aa79-994a829bc1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f7eea30-0390-40d4-b67d-5f3b60116efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(format_ds['error_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2b88a428-5bb3-4470-9a13-77744338d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(format_ds['error_ids']):\n",
    "    if i == [   0,  5113, 32000,    13,   963, 28350,  5855,    57,  4616,   611,\n",
    "           18,    85,  4729,   327, 5, 2]:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "888c1c4a-0d84-4910-bb31-f0b8efa29b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[637]['error_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aaed04f9-e230-4846-a922-f3cb08b6f3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "37def5d2-6038-4791-bc05-5b8c775c198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pos_weight = torch.randint(1, 100, (1,)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ad8da40-f542-4452-abad-839a121a9608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88613d55-79f9-4e8a-8eef-5e1dfbb3ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
